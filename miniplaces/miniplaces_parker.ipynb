{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Download-+-Preprocess-Data\" data-toc-modified-id=\"Download-+-Preprocess-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Download + Preprocess Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Download\" data-toc-modified-id=\"Download-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Download</a></span></li><li><span><a href=\"#Preprocess\" data-toc-modified-id=\"Preprocess-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preprocess</a></span></li></ul></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#~Inception-v4\" data-toc-modified-id=\"~Inception-v4-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>~Inception v4</a></span></li><li><span><a href=\"#VGG\" data-toc-modified-id=\"VGG-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>VGG</a></span></li></ul></li><li><span><a href=\"#Model-Comparison\" data-toc-modified-id=\"Model-Comparison-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Comparison</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [this class][class] (look at more of their notes later)\n",
    "\n",
    "Design principles\n",
    "* Reduce filter sizes (except possibly at the lowest layer), factorize filters aggressively\n",
    "* Use 1x1 convolutions to reduce and expand the number of feature maps judiciously\n",
    "* Use skip connections and/or create multiple paths through the network \n",
    "\n",
    "What else?\n",
    "* Training tricks and details: initialization, regularization, normalization\n",
    "* Training data augmentation\n",
    "* Averaging classifier outputs over multiple crops/flips\n",
    "* Ensembles of networks\n",
    "\n",
    "[class]: http://slazebni.cs.illinois.edu/spring17/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit results [here][submission] with team code: **KknPS9LrSKwM2cFXe9T2**\n",
    "\n",
    "See the leaderboard [here][lb].\n",
    "\n",
    "[submission]: http://miniplaces.csail.mit.edu/submit.php\n",
    "[lb]: http://miniplaces.csail.mit.edu/leaderboard.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T06:57:28.374772Z",
     "start_time": "2017-11-10T06:57:28.205263Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/csail.mit.edu/u/n/nhunt/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tnrange\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path = ['/scratch/nhunt/cv_parker/scripts'] + sys.path\n",
    "from utils import tf_init, get_next_run_num, load_data, output_file\n",
    "from layers import ConvLayer, MaxPoolLayer, AvgPoolLayer, BranchedLayer, MergeLayer, LayerModule, FlattenLayer, DenseLayer, GlobalAvgPoolLayer, DropoutLayer, GlobalMaxPoolLayer\n",
    "from models import CNN, BaseNN\n",
    "\n",
    "%matplotlib inline\n",
    "config = tf_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:36:16.402848Z",
     "start_time": "2017-11-10T04:36:16.358Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_inputs, train_labels, val_inputs, val_labels, test_inputs = load_data('miniplaces')\n",
    "n_classes = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Download + Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We end up with this file structure folder after first downloading everything:\n",
    "\n",
    "development_kit\n",
    " * README\n",
    " * ...\n",
    "\n",
    "data\n",
    " * labels\n",
    "    * categories.txt\n",
    "    * object_categories.txt\n",
    "    * train.txt\n",
    "    * val.txt\n",
    " * images\n",
    "     * train\n",
    "         * a\n",
    "             * abbey\n",
    "             * airport_terminal\n",
    "             * ...\n",
    "         * b\n",
    "         * ...\n",
    "     * val\n",
    "     * test\n",
    " * objects\n",
    "     * train\n",
    "         * a\n",
    "             * abbey\n",
    "             * airport_terminal\n",
    "             * ...\n",
    "         * b\n",
    "         * ...\n",
    "     * val\n",
    "\n",
    "The train images are stored in directories that correspond to their scene labels. All of the val and test images are stored directly in their directory. The labels for the val images (and for the test ones, for easier access) are in `development_kit/val.txt` and `/train.txt`.\n",
    "\n",
    "All of the images are .jpg files. The images have been resized to 128x128 to make the challenge easier (computationally; it may be harder in terms of achieving the same accuracy).\n",
    "\n",
    "The object notations are a special file that tells you the name of the image to which they correspond, where that image is (which folder), and then have bounding polygons (as a series of points) for the objects in the image, with classes for the objects. There are 3502 train images with object annotations and 371 validation images.\n",
    "\n",
    "**Read the README to get a better idea of the data before continuing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:36:28.872216Z",
     "start_time": "2017-11-10T04:36:16.532402Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -q http://6.869.csail.mit.edu/fa17/miniplaces/development_kit.tar.gz\n",
    "tar -xzf development_kit.tar.gz\n",
    "rm development_kit.tar.gz\n",
    "\n",
    "mkdir -p data/labels\n",
    "mv development_kit/data/* data/labels\n",
    "rm -r development_kit/data\n",
    "\n",
    "cd data\n",
    "wget -q http://6.869.csail.mit.edu/fa17/miniplaces/data.tar.gz\n",
    "tar -xzf data.tar.gz\n",
    "rm data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:36:29.009834Z",
     "start_time": "2017-11-10T04:36:28.875054Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = plt.imread('data/images/train/a/abbey/00000001.jpg')\n",
    "plt.imshow(img)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Preprocess\n",
    "* Put all train/val/test images in their own array for easy loading (the dataset is small enough that we can load all of them at once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:36:29.038769Z",
     "start_time": "2017-11-10T04:36:29.011816Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_imgs_together(split, convert_to_float=False, image_path='data/images', labels_path='data/labels/'):\n",
    "    \"\"\"\n",
    "    Reads in all of the images from this split and saves them into a single numpy array.\n",
    "    This should make the training easier and more efficient.\n",
    "    :param split: one of train, val, or test; which split of the data to process\n",
    "                  if split isn't test, the labels will also be saved into a numpy array\n",
    "    :param convert_to_float: if true, the image array is divided by 255 to conver the data to floats in [0, 1]\n",
    "    :param image_path: path to the first-level image directories (e.g. a, b, ...)\n",
    "    :param labels_path: path to the labels data (e.g. train.txt, val.txt)\n",
    "    \"\"\"\n",
    "\n",
    "    img_fnames = ! find $image_path/$split -name *.jpg | sort\n",
    "    imgs = [plt.imread(img_fname) for img_fname in img_fnames]\n",
    "\n",
    "    imgs = np.array(imgs)\n",
    "\n",
    "    if convert_to_float:\n",
    "        imgs = imgs / 255\n",
    "\n",
    "    np.save('{}/{}.npy'.format(image_path, split), imgs)\n",
    "\n",
    "    if split != 'test':  # no labels for test\n",
    "        labels = pd.read_csv('{}/{}.txt'.format(labels_path, split), sep=' ', header=None, usecols=[1]).iloc[:, 0].values\n",
    "\n",
    "        assert len(labels) == len(imgs)\n",
    "\n",
    "        np.save('{}/{}_labels.npy'.format(image_path, split), labels.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.629900Z",
     "start_time": "2017-11-10T04:36:29.042208Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'val', 'test']:\n",
    "    save_imgs_together(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~Inception v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.666546Z",
     "start_time": "2017-11-10T04:37:55.632859Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9ed58497300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparable_conv2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# tf.layers.separable_conv2d\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    labels = tf.placeholder(tf.int32, shape=None)\n",
    "    img = tf.placeholder(tf.float32, (None, 128, 128, 3))\n",
    "\n",
    "    layers = [\n",
    "        tf.layers.Conv2D(96, 11, 4, padding='SAME', activation=tf.nn.relu), # image size reduces to 32 * 32\n",
    "        tf.layers.MaxPooling2D(3, 2, padding='SAME'), # image size reduces to 16 * 16\n",
    "        tf.layers.Conv2D(256, 5, padding='SAME', activation=tf.nn.relu),\n",
    "        tf.layers.MaxPooling2D(3, 2, padding='SAME'), # image size reduces to 8 * 8\n",
    "        tf.layers.Conv2D(384, 3, padding='SAME', activation=tf.nn.relu),\n",
    "        tf.layers.Conv2D(384, 3, padding='SAME', activation=tf.nn.relu),\n",
    "        tf.layers.Conv2D(256, 3, padding='SAME', activation=tf.nn.relu),\n",
    "        tf.layers.MaxPooling2D(3, 2, padding='SAME'), # image size reduces to 4 * 4\n",
    "        tf.layers.Flatten(),\n",
    "        tf.layers.Dropout(0.5),\n",
    "        tf.layers.Dense(4096, activation=tf.nn.relu),\n",
    "        tf.layers.Dropout(0.5),\n",
    "        tf.layers.Dense(4096, activation=tf.nn.relu)\n",
    "    ]\n",
    "\n",
    "    hidden = img\n",
    "    for layer in layers:\n",
    "        hidden = layer(hidden)\n",
    "\n",
    "    logits = tf.layers.Dense(100, activation=None)(hidden)\n",
    "    preds = tf.nn.softmax(logits)\n",
    "    loss_op = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "    train_op = tf.train.AdagradOptimizer(.001).minimize(loss_op)\n",
    "    \n",
    "    _, acc_op = tf.metrics.accuracy(labels, tf.argmax(preds, axis=1))\n",
    "    \n",
    "    global_init = tf.global_variables_initializer()\n",
    "    local_init = tf.local_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_idx = list(range(len(train_labels)))\n",
    "val_idx = list(range(len(val_labels)))\n",
    "\n",
    "sess = tf.Session(config=config, graph=graph)\n",
    "sess.run(global_init)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\tnp.random.shuffle(train_idx)\n",
    "\t\n",
    "    sess.run(local_init)\n",
    "    train_loss = []\n",
    "    for batch in range(int(np.ceil(len(train_labels) / batch_size))):\n",
    "        batch_idx = train_idx[batch * batch_size : (batch + 1) * batch_size]\n",
    "        loss, train_acc, _ = sess.run([loss_op, acc_op, train_op], {img: train_inputs[batch_idx], labels: train_labels[batch_idx]})\n",
    "        train_loss.append(loss)\n",
    "\n",
    "    sess.run(local_init)\n",
    "    val_loss = []\n",
    "    for batch in range(int(np.ceil(len(val_labels) / batch_size))):\n",
    "        batch_idx = val_idx[batch * batch_size : (batch + 1) * batch_size]\n",
    "        loss, val_acc = sess.run([loss_op, acc_op], {img: val_inputs[batch_idx], labels: val_labels[batch_idx]})\n",
    "        val_loss.append(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}. Train Loss: {np.mean(train_loss):.3f}; Val Loss: {np.mean(val_loss):.3f}. Train Acc: {train_acc:.3f}; Val Acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.667559Z",
     "start_time": "2017-11-10T04:36:16.739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    # Image initial size 128 * 128\n",
    "    ConvLayer(96, 11, 4), # image size reduces to 32 * 32\n",
    "    MaxPoolLayer(3,2), # image size reduces to 16 * 16\n",
    "    ConvLayer(256, 5),\n",
    "    MaxPoolLayer(3,2), # image size reduces to 8 * 8\n",
    "    ConvLayer(384, 3),\n",
    "    ConvLayer(384, 3),\n",
    "    ConvLayer(256, 3),\n",
    "    MaxPoolLayer(3,2), # image size reduces to 4 * 4\n",
    "    FlattenLayer(),\n",
    "    DropoutLayer(0.5),\n",
    "    DenseLayer(4096),\n",
    "    DropoutLayer(0.5),\n",
    "    DenseLayer(4096)\n",
    "]\n",
    "\n",
    "cnn = CNN(layers, models_dir = \"/scratch/nhunt/cv_parker/miniplaces/models\", n_classes=n_classes)\n",
    "\n",
    "cnn.train(train_inputs[:1000], train_labels[:1000], val_inputs[:1000], val_labels[:1000], verbose=2, n_epochs=20,) # max_patience=20) # verbose 0 doesn't print anything, 2 progress bar in notebook, 1 terminal progress bar\n",
    "# cnn.train(train_inputs, train_labels, val_inputs, val_labels, verbose=2, n_epochs=1) # verbose 0 doesn't print anything, 2 progress bar in notebook, 1 terminal progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.668557Z",
     "start_time": "2017-11-10T04:36:16.740Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.score(val_inputs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.669655Z",
     "start_time": "2017-11-10T04:36:16.741Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = CNN(run_num=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.670719Z",
     "start_time": "2017-11-10T04:36:16.742Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.score(val_inputs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.671833Z",
     "start_time": "2017-11-10T04:36:16.743Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnn.score(val_inputs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.672903Z",
     "start_time": "2017-11-10T04:36:16.743Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = cnn.predict_proba(test_inputs)\n",
    "output_file(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.673908Z",
     "start_time": "2017-11-10T04:36:16.744Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prelu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.674966Z",
     "start_time": "2017-11-10T04:36:16.813Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = PretrainedCNN(n_classes=n_classes, dense_nodes=(1024, 1024), batch_size=64, config=config, cnn_module='vgg16',\n",
    "                   pretrained_weights=False)\n",
    "cnn.train(train_inputs, train_labels, val_inputs, val_labels, in_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.675963Z",
     "start_time": "2017-11-10T04:36:16.814Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cnn = PretrainedCNN(run_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.676930Z",
     "start_time": "2017-11-10T04:36:16.815Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.score(val_inputs, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.677868Z",
     "start_time": "2017-11-10T04:36:16.815Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = cnn.predict_proba(val_inputs)\n",
    "output_file(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "Adding batch norm: [0.23039998, 0.5126999]\n",
    "\n",
    "Submitted Models\n",
    "\n",
    "| Model | Acc@1 | Acc@5 | VAcc@1 | VAcc@5 | Notes | Run # |\n",
    "|-----|\n",
    "|  | .2429 | .4776 | 0.2509 | 0.5397 | | ??50-ish |\n",
    "| | .2691 | .5224 | 0.2900 | 0.5844 | batch norm and l2=.001 | 58 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-10T04:37:55.678854Z",
     "start_time": "2017-11-10T04:36:16.898Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = pd.read_hdf('models/log.h5', key='default').sort_values('dev_loss')\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
